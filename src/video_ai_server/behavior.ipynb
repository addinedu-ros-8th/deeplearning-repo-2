{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your system is cuda\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import platform\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from torch.cuda import empty_cache\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    print(\"your system is mac os\")\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "else:\n",
    "    print(\"your system is cuda\")\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/pepsi/dev_ws/mldl/Training/datasets/person'\n",
    "model_name = \"yolov8n.pt\"\n",
    "\n",
    "classes = ['person']\n",
    "nc = len(classes)\n",
    "yaml_file = 'data.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'train' : data_dir + '/train/',\n",
    "    'val' : data_dir + '/valid/',\n",
    "    'test' : data_dir + '/test/',\n",
    "    'nc' : nc,\n",
    "    'names' : classes,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "with open(data_dir + '/' + yaml_file, 'wt') as fw:\n",
    "    yaml.dump(data, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'names': ['person'], 'nc': 1, 'test': '/home/pepsi/dev_ws/mldl/Training/datasets/person/test/', 'train': '/home/pepsi/dev_ws/mldl/Training/datasets/person/train/', 'val': '/home/pepsi/dev_ws/mldl/Training/datasets/person/valid/'}\n"
     ]
    }
   ],
   "source": [
    "with open(data_dir + '/' + yaml_file, 'rt') as fr:\n",
    "    d = yaml.safe_load(fr)\n",
    "    print(type(d))\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = 100\n",
    "patience = 30\n",
    "batch = 32\n",
    "imgsz = 640\n",
    "LR = 0.001\n",
    "optimizer = 'AdamW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO(model_name).to(device)\n",
    "\n",
    "yolo_model.train(data=data_dir + '/' + yaml_file,\n",
    "            epochs = train_epoch,\n",
    "            patience=patience,\n",
    "            batch=batch,\n",
    "            imgsz = imgsz,\n",
    "            optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_best_model_path = '/Users/wjsong/dev_ws/Hosbot/runs/detect/train/weights/best.pt'\n",
    "\n",
    "YOLO_best_model = YOLO(YOLO_best_model_path).to(device)\n",
    "metrics = YOLO_best_model.val()\n",
    "\n",
    "for label, ap in zip(classes, metrics.box.maps):\n",
    "    print(label, ':', ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "yolo_best_model = '/home/pepsi/dev_ws/mldl/Training/runs/detect/train3/weights/best.pt'\n",
    "yolo_model = YOLO(yolo_best_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_YOLO_box(img, yolo_model, detect_cls):\n",
    "    box_results = yolo_model.predict(img, conf=0.6, verbose=False, show=False)\n",
    "    box_results = box_results[0].boxes\n",
    "\n",
    "    boxes = box_results.xyxy.cpu().tolist()\n",
    "    box_class = box_results.cls.cpu().tolist()\n",
    "\n",
    "    p1x1, p1y1, p1x2, p1y2 = 0, 0, 0, 0\n",
    "    p2x1, p2y1, p2x2, p2y2 = 0, 0, 0, 0\n",
    "    for idx, cls in enumerate(box_class):\n",
    "        if int(cls) == detect_cls:\n",
    "            p1x1, p1y1, p1x2, p1y2 = boxes[0]\n",
    "            p1x1, p1y1, p1x2, p1y2 = int(p1x1), int(p1y1), int(p1x2), int(p1y2)\n",
    "\n",
    "            if len(boxes) > 1:\n",
    "                p2x1, p2y1, p2x2, p2y2 = boxes[1]\n",
    "                p2x1, p2y1, p2x2, p2y2 = int(p2x1), int(p2y1), int(p2x2), int(p2y2)\n",
    "\n",
    "    return p1x1, p1y1, p1x2, p1y2, p2x1, p2y1, p2x2, p2y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_landmarks(results):\n",
    "    xyz_list = []\n",
    "    for landmark in results.pose_landmarks.landmark:\n",
    "        xyz_list.append(landmark.x)\n",
    "        xyz_list.append(landmark.y)\n",
    "        xyz_list.append(landmark.z)\n",
    "    return xyz_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data_xyz_list_list(xyz_list_list, p1x1, p1y1, p1x2, p1y2, p2x1, p2y1, p2x2, p2y2, xyz_list):\n",
    "    xyz_list.append(abs(p1x1 - p2x1) / 640)\n",
    "    xyz_list.append(abs(p1x2 - p2x2) / 640)\n",
    "    xyz_list.append(abs(p1y1 - p2y1) / 640)\n",
    "    xyz_list.append(abs(p1y2 - p2y2) / 640)\n",
    "    xyz_list_list.append(xyz_list)\n",
    "\n",
    "    return xyz_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(mp_pose, video_path, detect_cls):\n",
    "    xyz_list_list = []\n",
    "    poses = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if cap.isOpened():\n",
    "        while True:\n",
    "            ret, img = cap.read()\n",
    "            if ret == True:\n",
    "                xyz_list = []\n",
    "                img = cv2.resize(img, (640, 640))\n",
    "                results = poses.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                if not results.pose_landmarks: continue\n",
    "\n",
    "                xyz_list = get_pose_landmarks(results)\n",
    "                p1x1, p1y1, p1x2, p1y2, p2x1, p2y1, p2x2, p2y2 = get_YOLO_box(img, yolo_model, detect_cls)\n",
    "\n",
    "                if (p1x1 == 0 and p1y1 == 0 and p1x2 == 0 and p1y2== 0) and (p2x1 == 0 and p2y1 == 0 and p2x2 == 0 and p2y2== 0): continue\n",
    "\n",
    "                xyz_list_list = append_data_xyz_list_list(xyz_list_list, p1x1, p1y1, p1x2, p1y2, p2x1, p2y1, p2x2, p2y2, xyz_list)\n",
    "\n",
    "                cv2.waitKey(1)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return xyz_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743662616.421273   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662616.425521   14915 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662616.524199   14902 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662616.564774   14909 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "  6%|▋         | 1/16 [00:30<07:44, 30.96s/it]I0000 00:00:1743662647.379519   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662647.381604   14947 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662647.502666   14935 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662647.575477   14933 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 12%|█▎        | 2/16 [00:56<06:30, 27.87s/it]I0000 00:00:1743662673.091642   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662673.093118   15016 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662673.206951   15010 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662673.274935   15009 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 19%|█▉        | 3/16 [01:25<06:08, 28.36s/it]I0000 00:00:1743662702.037566   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662702.043362   15070 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662702.213451   15057 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662702.295978   15060 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 25%|██▌       | 4/16 [01:51<05:29, 27.42s/it]I0000 00:00:1743662728.021897   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662728.027394   15101 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662728.198404   15095 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662728.263478   15096 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 31%|███▏      | 5/16 [02:21<05:11, 28.30s/it]I0000 00:00:1743662757.862830   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662757.864139   15141 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662758.015847   15129 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662758.079076   15132 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 38%|███▊      | 6/16 [02:50<04:46, 28.64s/it]I0000 00:00:1743662787.183615   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662787.187947   15176 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662787.316128   15171 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662787.364243   15167 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 44%|████▍     | 7/16 [03:17<04:12, 28.09s/it]I0000 00:00:1743662814.124868   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662814.126236   15212 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662814.251769   15206 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662814.311154   15200 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 50%|█████     | 8/16 [03:50<03:56, 29.57s/it]I0000 00:00:1743662846.877109   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662846.878616   15241 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662847.001308   15237 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662847.050246   15231 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 56%|█████▋    | 9/16 [04:14<03:15, 27.97s/it]I0000 00:00:1743662871.325225   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662871.326842   15269 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662871.454299   15258 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662871.508864   15256 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 62%|██████▎   | 10/16 [04:40<02:42, 27.15s/it]I0000 00:00:1743662896.649879   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662896.654753   15299 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662896.772460   15292 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662896.814937   15288 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 69%|██████▉   | 11/16 [05:04<02:12, 26.42s/it]I0000 00:00:1743662921.409636   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662921.410970   15326 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662921.541775   15313 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662921.633825   15316 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 75%|███████▌  | 12/16 [05:30<01:45, 26.30s/it]I0000 00:00:1743662947.418337   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662947.419819   15354 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662947.529649   15348 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662947.614235   15349 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 81%|████████▏ | 13/16 [05:55<01:16, 25.63s/it]I0000 00:00:1743662971.514404   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662971.515706   15416 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662971.674496   15408 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662971.768878   15406 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 88%|████████▊ | 14/16 [06:22<00:52, 26.13s/it]I0000 00:00:1743662998.813084   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743662998.814666   15457 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743662998.955500   15444 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743662999.017936   15454 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 94%|█████████▍| 15/16 [06:47<00:25, 25.92s/it]I0000 00:00:1743663024.235588   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743663024.236923   15491 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743663024.392861   15480 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743663024.441098   15481 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "100%|██████████| 16/16 [07:15<00:00, 27.23s/it]\n"
     ]
    }
   ],
   "source": [
    "Video_path = './datasets/pose/train2'\n",
    "video_name_list = os.listdir(Video_path)\n",
    "dataset = []\n",
    "length = 18\n",
    "detect_cls = 0\n",
    "\n",
    "for video_name in tqdm(video_name_list):\n",
    "    if 'normal' in video_name: label = 0\n",
    "    elif 'fighting' in video_name: label = 1\n",
    "    elif 'lying' in video_name: label = 2\n",
    "    elif 'smoking' in video_name: label = 3\n",
    "\n",
    "    pose_data = generate_dataset(mp_pose, '{}/{}'.format(Video_path, video_name), detect_cls)\n",
    "\n",
    "    for idx in range(0, len(pose_data), int(length)):\n",
    "        seq_list = pose_data[idx : idx + length]\n",
    "        if len(seq_list) == length:\n",
    "            dataset.append({'key' : label, 'value': seq_list})\n",
    "\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data [0.4896206259727478, 0.2955930233001709, -0.18025879561901093, 0.4944857954978943, 0.2864210605621338, -0.16384553909301758, 0.49717432260513306, 0.28647130727767944, -0.16392391920089722, 0.49956101179122925, 0.2866463363170624, -0.16397570073604584, 0.48687291145324707, 0.2858287990093231, -0.16399261355400085, 0.484457790851593, 0.28549468517303467, -0.16400600969791412, 0.48215824365615845, 0.28534311056137085, -0.164031520485878, 0.5022401809692383, 0.28879401087760925, -0.06746762245893478, 0.4802505373954773, 0.2882291376590729, -0.06947915256023407, 0.49430474638938904, 0.3035470247268677, -0.1443376988172531, 0.4861088693141937, 0.3035762906074524, -0.1451880782842636, 0.5216508507728577, 0.34751608967781067, -0.033903468400239944, 0.46449166536331177, 0.34376296401023865, -0.025703245773911476, 0.526207447052002, 0.41610851883888245, -0.0362040139734745, 0.45846644043922424, 0.39264366030693054, -0.15504685044288635, 0.5269924998283386, 0.47789448499679565, -0.061018239706754684, 0.4789808690547943, 0.3399559557437897, -0.3223150074481964, 0.5291333198547363, 0.49674439430236816, -0.07777421921491623, 0.4840066432952881, 0.32468777894973755, -0.35556045174598694, 0.5234036445617676, 0.4977385401725769, -0.09156006574630737, 0.48374414443969727, 0.3196248412132263, -0.35292232036590576, 0.5223623514175415, 0.4904000759124756, -0.06658168137073517, 0.48270383477211, 0.3272917866706848, -0.3257199823856354, 0.5101986527442932, 0.4722256064414978, 0.0015322824474424124, 0.47672519087791443, 0.4695216715335846, -0.0015172562561929226, 0.5071491003036499, 0.5691659450531006, -0.006506309844553471, 0.47853565216064453, 0.5634214878082275, -0.0068022399209439754, 0.5057638883590698, 0.6460983753204346, 0.14038488268852234, 0.4809715151786804, 0.6475964784622192, 0.1264568269252777, 0.5014756321907043, 0.6478114128112793, 0.14833152294158936, 0.4818570017814636, 0.6486036777496338, 0.13350117206573486, 0.5104873776435852, 0.6506025791168213, 0.04794316738843918, 0.48292064666748047, 0.6736917495727539, 0.02293916791677475, 0.446875, 0.5359375, 0.24375, 0.696875]\n",
      "input data length 103\n"
     ]
    }
   ],
   "source": [
    "print('input data', dataset[0]['value'][0])\n",
    "print('input data length', len(dataset[0]['value'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, seq_list):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_list:\n",
    "            self.y.append(dic['key'])\n",
    "            self.X.append(dic['value'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = [0.7, 0.2, 0.1]\n",
    "train_len = int(len(dataset) * split_ratio[0])\n",
    "val_len = int(len(dataset) * split_ratio[1])\n",
    "test_len = len(dataset) - train_len - val_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(dataset)\n",
    "train_data, valid_data, test_data = random_split(train_dataset, [train_len, val_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8)\n",
    "val_loader = DataLoader(valid_data, batch_size=8)\n",
    "test_loader = DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_layers=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(103, 128, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.layer_norm1 = nn.LayerNorm(256)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "\n",
    "        self.lstm2 = nn.LSTM(256, 64, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.layer_norm2 = nn.LayerNorm(128)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "\n",
    "        self.lstm3 = nn.LSTM(128, 32, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.layer_norm3 = nn.LayerNorm(64)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "\n",
    "        self.attention = nn.Linear(64, 1)\n",
    "        self.fc = nn.Linear(64, 4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.layer_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        attention_weights = torch.softmax(self.attention(x), dim=1)\n",
    "        x = torch.sum(attention_weights * x, dim=1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    global net, loss_fn, optim\n",
    "    net = LSTM().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = AdamW(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_log():\n",
    "    global iter_log, tloss_log, tacc_log, vloss_log, vacc_log, log_stack, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    log_stack, time_log = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_valid_log(_vloss, _vacc):\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last(log_list):\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log():\n",
    "    train_loss = round(float(last(tloss_log)), 3)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 3)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 3)\n",
    "\n",
    "    log_str = 'Epoch: {:3}| T_Loss {:5} | T_acc {:5}| V_Loss {:5}| V_acc {:5} | {:5}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent)\n",
    "\n",
    "    log_stack.append(log_str) #프린트 준비\n",
    "\n",
    "    for idx in reversed(range(len(log_stack))):\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "def epoch_not_finished():\n",
    "    return epoch_cnt < maximum_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(data_loader, mode='train'):\n",
    "    global epoch_cnt\n",
    "\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.type(torch.LongTensor).to(device)\n",
    "\n",
    "        if mode == 'train' : net.train()\n",
    "        else: net.eval()\n",
    "\n",
    "        result = net(data)\n",
    "        _, out = torch.max(result, 1)\n",
    "\n",
    "        loss = loss_fn(result, label)\n",
    "        iter_loss.append(loss.item())\n",
    "\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            last_grad_performed = True\n",
    "\n",
    "        acc_partial = (out == label).float().sum()\n",
    "        acc_partial = acc_partial / len(label)\n",
    "        iter_acc.append(acc_partial.item())\n",
    "\n",
    "\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "\n",
    "    clear_memory()\n",
    "\n",
    "    return np.average(iter_loss), np.average(iter_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "maximum_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  41| T_Loss 0.037 | T_acc 0.995| V_Loss 0.234| V_acc 0.946 | 0.513\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  42| T_Loss 0.097 | T_acc 0.967| V_Loss 0.291| V_acc 0.911 | 0.496\n",
      "Epoch:  41| T_Loss 0.037 | T_acc 0.995| V_Loss 0.234| V_acc 0.946 | 0.513\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  43| T_Loss 0.077 | T_acc 0.962| V_Loss  0.12| V_acc 0.964 | 0.496\n",
      "Epoch:  42| T_Loss 0.097 | T_acc 0.967| V_Loss 0.291| V_acc 0.911 | 0.496\n",
      "Epoch:  41| T_Loss 0.037 | T_acc 0.995| V_Loss 0.234| V_acc 0.946 | 0.513\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  44| T_Loss 0.024 | T_acc 0.995| V_Loss 0.094| V_acc 0.982 | 0.503\n",
      "Epoch:  43| T_Loss 0.077 | T_acc 0.962| V_Loss  0.12| V_acc 0.964 | 0.496\n",
      "Epoch:  42| T_Loss 0.097 | T_acc 0.967| V_Loss 0.291| V_acc 0.911 | 0.496\n",
      "Epoch:  41| T_Loss 0.037 | T_acc 0.995| V_Loss 0.234| V_acc 0.946 | 0.513\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  45| T_Loss 0.024 | T_acc 0.989| V_Loss 0.096| V_acc 0.982 | 0.514\n",
      "Epoch:  44| T_Loss 0.024 | T_acc 0.995| V_Loss 0.094| V_acc 0.982 | 0.503\n",
      "Epoch:  43| T_Loss 0.077 | T_acc 0.962| V_Loss  0.12| V_acc 0.964 | 0.496\n",
      "Epoch:  42| T_Loss 0.097 | T_acc 0.967| V_Loss 0.291| V_acc 0.911 | 0.496\n",
      "Epoch:  41| T_Loss 0.037 | T_acc 0.995| V_Loss 0.234| V_acc 0.946 | 0.513\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  46| T_Loss 0.027 | T_acc 0.989| V_Loss 0.082| V_acc 0.982 | 0.508\n",
      "Epoch:  45| T_Loss 0.024 | T_acc 0.989| V_Loss 0.096| V_acc 0.982 | 0.514\n",
      "Epoch:  44| T_Loss 0.024 | T_acc 0.995| V_Loss 0.094| V_acc 0.982 | 0.503\n",
      "Epoch:  43| T_Loss 0.077 | T_acc 0.962| V_Loss  0.12| V_acc 0.964 | 0.496\n",
      "Epoch:  42| T_Loss 0.097 | T_acc 0.967| V_Loss 0.291| V_acc 0.911 | 0.496\n",
      "Epoch:  41| T_Loss 0.037 | T_acc 0.995| V_Loss 0.234| V_acc 0.946 | 0.513\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  47| T_Loss 0.008 | T_acc   1.0| V_Loss 0.113| V_acc 0.982 | 0.506\n",
      "Epoch:  46| T_Loss 0.027 | T_acc 0.989| V_Loss 0.082| V_acc 0.982 | 0.508\n",
      "Epoch:  45| T_Loss 0.024 | T_acc 0.989| V_Loss 0.096| V_acc 0.982 | 0.514\n",
      "Epoch:  44| T_Loss 0.024 | T_acc 0.995| V_Loss 0.094| V_acc 0.982 | 0.503\n",
      "Epoch:  43| T_Loss 0.077 | T_acc 0.962| V_Loss  0.12| V_acc 0.964 | 0.496\n",
      "Epoch:  42| T_Loss 0.097 | T_acc 0.967| V_Loss 0.291| V_acc 0.911 | 0.496\n",
      "Epoch:  41| T_Loss 0.037 | T_acc 0.995| V_Loss 0.234| V_acc 0.946 | 0.513\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  48| T_Loss 0.005 | T_acc   1.0| V_Loss 0.111| V_acc 0.982 | 0.509\n",
      "Epoch:  47| T_Loss 0.008 | T_acc   1.0| V_Loss 0.113| V_acc 0.982 | 0.506\n",
      "Epoch:  46| T_Loss 0.027 | T_acc 0.989| V_Loss 0.082| V_acc 0.982 | 0.508\n",
      "Epoch:  45| T_Loss 0.024 | T_acc 0.989| V_Loss 0.096| V_acc 0.982 | 0.514\n",
      "Epoch:  44| T_Loss 0.024 | T_acc 0.995| V_Loss 0.094| V_acc 0.982 | 0.503\n",
      "Epoch:  43| T_Loss 0.077 | T_acc 0.962| V_Loss  0.12| V_acc 0.964 | 0.496\n",
      "Epoch:  42| T_Loss 0.097 | T_acc 0.967| V_Loss 0.291| V_acc 0.911 | 0.496\n",
      "Epoch:  41| T_Loss 0.037 | T_acc 0.995| V_Loss 0.234| V_acc 0.946 | 0.513\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  49| T_Loss 0.003 | T_acc   1.0| V_Loss 0.117| V_acc 0.982 |   0.5\n",
      "Epoch:  48| T_Loss 0.005 | T_acc   1.0| V_Loss 0.111| V_acc 0.982 | 0.509\n",
      "Epoch:  47| T_Loss 0.008 | T_acc   1.0| V_Loss 0.113| V_acc 0.982 | 0.506\n",
      "Epoch:  46| T_Loss 0.027 | T_acc 0.989| V_Loss 0.082| V_acc 0.982 | 0.508\n",
      "Epoch:  45| T_Loss 0.024 | T_acc 0.989| V_Loss 0.096| V_acc 0.982 | 0.514\n",
      "Epoch:  44| T_Loss 0.024 | T_acc 0.995| V_Loss 0.094| V_acc 0.982 | 0.503\n",
      "Epoch:  43| T_Loss 0.077 | T_acc 0.962| V_Loss  0.12| V_acc 0.964 | 0.496\n",
      "Epoch:  42| T_Loss 0.097 | T_acc 0.967| V_Loss 0.291| V_acc 0.911 | 0.496\n",
      "Epoch:  41| T_Loss 0.037 | T_acc 0.995| V_Loss 0.234| V_acc 0.946 | 0.513\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "Epoch:  50| T_Loss 0.003 | T_acc   1.0| V_Loss 0.117| V_acc 0.982 | 0.516\n",
      "Epoch:  49| T_Loss 0.003 | T_acc   1.0| V_Loss 0.117| V_acc 0.982 |   0.5\n",
      "Epoch:  48| T_Loss 0.005 | T_acc   1.0| V_Loss 0.111| V_acc 0.982 | 0.509\n",
      "Epoch:  47| T_Loss 0.008 | T_acc   1.0| V_Loss 0.113| V_acc 0.982 | 0.506\n",
      "Epoch:  46| T_Loss 0.027 | T_acc 0.989| V_Loss 0.082| V_acc 0.982 | 0.508\n",
      "Epoch:  45| T_Loss 0.024 | T_acc 0.989| V_Loss 0.096| V_acc 0.982 | 0.514\n",
      "Epoch:  44| T_Loss 0.024 | T_acc 0.995| V_Loss 0.094| V_acc 0.982 | 0.503\n",
      "Epoch:  43| T_Loss 0.077 | T_acc 0.962| V_Loss  0.12| V_acc 0.964 | 0.496\n",
      "Epoch:  42| T_Loss 0.097 | T_acc 0.967| V_Loss 0.291| V_acc 0.911 | 0.496\n",
      "Epoch:  41| T_Loss 0.037 | T_acc 0.995| V_Loss 0.234| V_acc 0.946 | 0.513\n",
      "Epoch:  40| T_Loss 0.034 | T_acc 0.989| V_Loss 0.258| V_acc 0.946 | 0.526\n",
      "Epoch:  39| T_Loss 0.073 | T_acc 0.978| V_Loss 0.272| V_acc 0.946 | 0.535\n",
      "Epoch:  38| T_Loss 0.194 | T_acc 0.967| V_Loss 0.217| V_acc 0.946 | 0.505\n",
      "Epoch:  37| T_Loss 0.182 | T_acc 0.946| V_Loss  0.09| V_acc 0.964 | 0.507\n",
      "Epoch:  36| T_Loss 0.153 | T_acc 0.962| V_Loss 0.151| V_acc 0.964 | 0.498\n",
      "Epoch:  35| T_Loss 0.023 | T_acc 0.995| V_Loss 0.243| V_acc 0.946 | 0.611\n",
      "Epoch:  34| T_Loss 0.047 | T_acc 0.984| V_Loss 0.155| V_acc 0.964 | 0.501\n",
      "Epoch:  33| T_Loss 0.068 | T_acc 0.973| V_Loss 0.258| V_acc 0.946 |   0.5\n",
      "Epoch:  32| T_Loss 0.042 | T_acc 0.978| V_Loss 0.279| V_acc 0.946 | 0.497\n",
      "Epoch:  31| T_Loss 0.031 | T_acc 0.989| V_Loss 0.277| V_acc 0.929 | 0.489\n",
      "Epoch:  30| T_Loss 0.028 | T_acc 0.989| V_Loss 0.256| V_acc 0.946 | 0.493\n",
      "Epoch:  29| T_Loss  0.07 | T_acc 0.973| V_Loss 0.223| V_acc 0.946 | 0.519\n",
      "Epoch:  28| T_Loss 0.106 | T_acc 0.962| V_Loss 0.347| V_acc 0.911 | 0.531\n",
      "Epoch:  27| T_Loss 0.095 | T_acc 0.967| V_Loss 0.187| V_acc 0.929 | 0.552\n",
      "Epoch:  26| T_Loss 0.044 | T_acc 0.984| V_Loss  0.31| V_acc 0.946 | 0.537\n",
      "Epoch:  25| T_Loss 0.039 | T_acc 0.989| V_Loss 0.202| V_acc 0.946 | 0.502\n",
      "Epoch:  24| T_Loss  0.11 | T_acc 0.962| V_Loss 0.173| V_acc 0.946 | 0.504\n",
      "Epoch:  23| T_Loss 0.118 | T_acc 0.957| V_Loss 0.242| V_acc 0.911 | 0.494\n",
      "Epoch:  22| T_Loss 0.047 | T_acc 0.989| V_Loss 0.269| V_acc 0.946 | 0.508\n",
      "Epoch:  21| T_Loss  0.06 | T_acc 0.984| V_Loss 0.112| V_acc 0.982 | 0.502\n",
      "Epoch:  20| T_Loss 0.185 | T_acc 0.935| V_Loss  0.16| V_acc 0.964 | 0.511\n",
      "Epoch:  19| T_Loss  0.05 | T_acc 0.989| V_Loss 0.103| V_acc 0.982 | 0.508\n",
      "Epoch:  18| T_Loss 0.086 | T_acc 0.973| V_Loss 0.138| V_acc 0.964 |   0.5\n",
      "Epoch:  17| T_Loss 0.132 | T_acc 0.951| V_Loss 0.105| V_acc 0.982 | 0.506\n",
      "Epoch:  16| T_Loss 0.131 | T_acc  0.94| V_Loss 0.261| V_acc 0.929 | 0.489\n",
      "Epoch:  15| T_Loss 0.092 | T_acc 0.973| V_Loss 0.095| V_acc 0.982 | 0.511\n",
      "Epoch:  14| T_Loss 0.147 | T_acc  0.94| V_Loss 0.063| V_acc 0.982 | 0.529\n",
      "Epoch:  13| T_Loss 0.279 | T_acc 0.918| V_Loss 0.122| V_acc 0.982 | 0.526\n",
      "Epoch:  12| T_Loss 0.052 | T_acc 0.989| V_Loss 0.098| V_acc 0.982 |  0.52\n",
      "Epoch:  11| T_Loss 0.138 | T_acc 0.935| V_Loss  0.12| V_acc 0.964 | 0.514\n",
      "Epoch:  10| T_Loss 0.098 | T_acc 0.973| V_Loss 0.091| V_acc 0.982 |  0.51\n",
      "Epoch:   9| T_Loss 0.117 | T_acc 0.951| V_Loss 0.208| V_acc 0.929 | 0.643\n",
      "Epoch:   8| T_Loss 0.185 | T_acc 0.935| V_Loss 0.177| V_acc 0.929 | 0.541\n",
      "Epoch:   7| T_Loss 0.379 | T_acc  0.87| V_Loss 0.181| V_acc 0.964 |  0.47\n",
      "Epoch:   6| T_Loss 0.233 | T_acc 0.918| V_Loss 0.387| V_acc 0.804 | 1.151\n",
      "Epoch:   5| T_Loss 0.342 | T_acc 0.862| V_Loss 0.143| V_acc 0.982 | 1.055\n",
      "Epoch:   4| T_Loss 0.309 | T_acc 0.897| V_Loss 0.211| V_acc 0.911 | 1.035\n",
      "Epoch:   3| T_Loss 0.434 | T_acc 0.781| V_Loss 0.269| V_acc 0.929 | 0.906\n",
      "Epoch:   2| T_Loss 0.649 | T_acc 0.703| V_Loss 0.385| V_acc 0.857 | 0.917\n",
      "Epoch:   1| T_Loss 0.986 | T_acc 0.524| V_Loss 0.703| V_acc 0.661 | 0.855\n",
      "\n",
      " Training completed!\n"
     ]
    }
   ],
   "source": [
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = epoch(train_loader, mode='train')\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(val_loader, mode= 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 1.0\n",
      "Test Loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_loss, test_acc = epoch(test_loader, mode='test')\n",
    "    test_acc = round(test_acc, 4)\n",
    "    test_loss = round(test_loss, 4)\n",
    "    print('Test Acc: {}'.format(test_acc))\n",
    "    print('Test Loss: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "model_path = './models/lstm_model.pth'\n",
    "\n",
    "torch.save(net.state_dict(), model_path)\n",
    "print('모델이 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 성공적으로 불러와졌습니다.\n"
     ]
    }
   ],
   "source": [
    "model_path = './models/lstm_model.pth'\n",
    "\n",
    "lstm_model = LSTM().to(device)\n",
    "lstm_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "lstm_model.eval()\n",
    "print(\"모델이 성공적으로 불러와졌습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743663130.583804   12532 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743663130.587448   15527 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743663130.669712   15519 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743663130.714371   15523 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "length = 18\n",
    "detect_cls = 0\n",
    "\n",
    "lstm_model.eval()\n",
    "dataset = []\n",
    "status = 'None'\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "poses = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "xyz_list_list = []\n",
    "status_dict = {0: 'normal', 1: 'fighting', 2: 'lying', 3: 'smoking'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    RuntimeError(\"카메라 열기 실패\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:  # 프레임 읽기 실패 시 종료\n",
    "        break\n",
    "\n",
    "    # 프레임 크기 조정 (선택 사항, YOLO 모델에 따라 필요)\n",
    "    frame = cv2.resize(frame, (640, 640))\n",
    "\n",
    "    # Mediapipe 포즈 추출\n",
    "    results = poses.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    xyz_list = []\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        # 포즈 랜드마크 추출 및 그리기\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            xyz_list.append(landmark.x)\n",
    "            xyz_list.append(landmark.y)\n",
    "            xyz_list.append(landmark.z)\n",
    "\n",
    "        # YOLO 박스 예측\n",
    "        box_results = yolo_model.predict(frame, conf=0.6, verbose=False, show=False)[0].boxes\n",
    "        boxes = box_results.xyxy.cpu().tolist()\n",
    "        box_class = box_results.cls.cpu().tolist()\n",
    "\n",
    "        p1x1, p1y1, p1x2, p1y2 = 0, 0, 0, 0\n",
    "        p2x1, p2y1, p2x2, p2y2 = 0, 0, 0, 0\n",
    "        for idx, cls in enumerate(box_class):\n",
    "            if int(cls) == detect_cls:\n",
    "                p1x1, p1y1, p1x2, p1y2 = map(int, boxes[0])\n",
    "                if len(boxes) > 1:\n",
    "                    p2x1, p2y1, p2x2, p2y2 = map(int, boxes[1])\n",
    "\n",
    "                break\n",
    "\n",
    "        # YOLO 박스 좌표 정규화 후 추가\n",
    "        xyz_list.extend([abs(p1x1 - p2x1) / 640, abs(p1x2 - p2x2) / 640, abs(p1y1 - p2y1) / 640, abs(p1y2 - p2y2) / 640])\n",
    "        xyz_list_list.append(xyz_list)\n",
    "\n",
    "    # 시퀀스 길이에 도달하면 LSTM 예측 수행\n",
    "    if len(xyz_list_list) == length:\n",
    "        dataset = [{'key': 0, 'value': xyz_list_list}]  # 임시 라벨 0 사용\n",
    "        dataset = MyDataset(dataset)\n",
    "        dataset_loader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "        for data, _ in dataset_loader:\n",
    "            data = data.to(device)\n",
    "            with torch.no_grad():\n",
    "                result = lstm_model(data)\n",
    "                _, out = torch.max(result, 1)\n",
    "                status = status_dict.get(out.item(), 'Unknown')\n",
    "\n",
    "        xyz_list_list = []  # 시퀀스 초기화\n",
    "\n",
    "    # 상태 텍스트 표시\n",
    "    cv2.putText(frame, status, (10, 50), cv2.FONT_HERSHEY_COMPLEX, 1.5, (255, 0, 0), 2)\n",
    "\n",
    "    # 프레임 표시\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # 'q' 키로 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 리소스 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hosbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
